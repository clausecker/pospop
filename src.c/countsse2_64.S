#ifdef __amd64__

#include "kernelsse2.S"

	.type   accum8, @function
	.balign	16
accum8:	movdqa  xmm4, xmm8
	punpcklwd xmm8, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm12
	punpcklwd xmm5, xmm7
	punpckhwd xmm12, xmm7
	paddd   xmm8, xmm5
	paddd   xmm12, xmm4
	movdqa  xmm4, xmm9
	punpcklwd xmm9, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm13
	punpcklwd xmm5, xmm7
	punpckhwd xmm13, xmm7
	paddd   xmm9, xmm5
	paddd   xmm13, xmm4
	movdqa  xmm4, xmm10
	punpcklwd xmm10, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm14
	punpcklwd xmm5, xmm7
	punpckhwd xmm14, xmm7
	paddd   xmm10, xmm5
	paddd   xmm14, xmm4
	movdqa  xmm4, xmm11
	punpcklwd xmm11, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm15
	punpcklwd xmm5, xmm7
	punpckhwd xmm15, xmm7
	paddd   xmm11, xmm5
	paddd   xmm15, xmm4
	paddd   xmm8, xmm10
	paddd   xmm9, xmm11
	paddd   xmm12, xmm14
	paddd   xmm13, xmm15
	paddd   xmm8, xmm9
	movdqa  xmm4, xmm8
	punpckldq xmm8, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi]
	paddq   xmm5, xmm8
	movdqu  [rdi], xmm5
	movdqu  xmm5, [rdi+0x10]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x10], xmm5
	paddd   xmm12, xmm13
	movdqa  xmm4, xmm12
	punpckldq xmm12, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x20]
	paddq   xmm5, xmm12
	movdqu  [rdi+0x20], xmm5
	movdqu  xmm5, [rdi+0x30]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x30], xmm5
	ret
	.size	accum8, .-accum8

	.type	accum16, @function
	.balign	16
accum16:
	movdqa  xmm4, xmm8
	punpcklwd xmm8, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm12
	punpcklwd xmm5, xmm7
	punpckhwd xmm12, xmm7
	paddd   xmm8, xmm5
	paddd   xmm12, xmm4
	movdqa  xmm4, xmm9
	punpcklwd xmm9, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm13
	punpcklwd xmm5, xmm7
	punpckhwd xmm13, xmm7
	paddd   xmm9, xmm5
	paddd   xmm13, xmm4
	movdqa  xmm4, xmm10
	punpcklwd xmm10, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm14
	punpcklwd xmm5, xmm7
	punpckhwd xmm14, xmm7
	paddd   xmm10, xmm5
	paddd   xmm14, xmm4
	movdqa  xmm4, xmm11
	punpcklwd xmm11, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm15
	punpcklwd xmm5, xmm7
	punpckhwd xmm15, xmm7
	paddd   xmm11, xmm5
	paddd   xmm15, xmm4
	paddd   xmm8, xmm10
	movdqa  xmm4, xmm8
	punpckldq xmm8, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi]
	paddq   xmm5, xmm8
	movdqu  [rdi], xmm5
	movdqu  xmm5, [rdi+0x10]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x10], xmm5
	paddd   xmm12, xmm14
	movdqa  xmm4, xmm12
	punpckldq xmm12, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x20]
	paddq   xmm5, xmm12
	movdqu  [rdi+0x20], xmm5
	movdqu  xmm5, [rdi+0x30]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x30], xmm5
	paddd   xmm9, xmm11
	movdqa  xmm4, xmm9
	punpckldq xmm9, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x40]
	paddq   xmm5, xmm9
	movdqu  [rdi+0x40], xmm5
	movdqu  xmm5, [rdi+0x50]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x50], xmm5
	paddd   xmm13, xmm15
	movdqa  xmm4, xmm13
	punpckldq xmm13, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x60]
	paddq   xmm5, xmm13
	movdqu  [rdi+0x60], xmm5
	movdqu  xmm5, [rdi+0x70]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x70], xmm5
	ret
	.size	accum16, .-accum16

	.type   accum32, @function
	.balign	16
accum32:
	movdqa  xmm4, xmm8
	punpcklwd xmm8, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm12
	punpcklwd xmm5, xmm7
	punpckhwd xmm12, xmm7
	paddd   xmm8, xmm5
	paddd   xmm12, xmm4
	movdqa  xmm4, xmm8
	punpckldq xmm8, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi]
	paddq   xmm5, xmm8
	movdqu  [rdi], xmm5
	movdqu  xmm5, [rdi+0x10]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x10], xmm5
	movdqa  xmm4, xmm12
	punpckldq xmm12, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x20]
	paddq   xmm5, xmm12
	movdqu  [rdi+0x20], xmm5
	movdqu  xmm5, [rdi+0x30]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x30], xmm5
	movdqa  xmm4, xmm9
	punpcklwd xmm9, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm13
	punpcklwd xmm5, xmm7
	punpckhwd xmm13, xmm7
	paddd   xmm9, xmm5
	paddd   xmm13, xmm4
	movdqa  xmm4, xmm9
	punpckldq xmm9, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x40]
	paddq   xmm5, xmm9
	movdqu  [rdi+0x40], xmm5
	movdqu  xmm5, [rdi+0x50]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x50], xmm5
	movdqa  xmm4, xmm13
	punpckldq xmm13, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x60]
	paddq   xmm5, xmm13
	movdqu  [rdi+0x60], xmm5
	movdqu  xmm5, [rdi+0x70]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x70], xmm5
	movdqa  xmm4, xmm10
	punpcklwd xmm10, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm14
	punpcklwd xmm5, xmm7
	punpckhwd xmm14, xmm7
	paddd   xmm10, xmm5
	paddd   xmm14, xmm4
	movdqa  xmm4, xmm10
	punpckldq xmm10, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x80]
	paddq   xmm5, xmm10
	movdqu  [rdi+0x80], xmm5
	movdqu  xmm5, [rdi+0x90]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x90], xmm5
	movdqa  xmm4, xmm14
	punpckldq xmm14, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xA0]
	paddq   xmm5, xmm14
	movdqu  [rdi+0xA0], xmm5
	movdqu  xmm5, [rdi+0xB0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xB0], xmm5
	movdqa  xmm4, xmm11
	punpcklwd xmm11, xmm7
	punpckhwd xmm4, xmm7
	movdqa  xmm5, xmm15
	punpcklwd xmm5, xmm7
	punpckhwd xmm15, xmm7
	paddd   xmm11, xmm5
	paddd   xmm15, xmm4
	movdqa  xmm4, xmm11
	punpckldq xmm11, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xC0]
	paddq   xmm5, xmm11
	movdqu  [rdi+0xC0], xmm5
	movdqu  xmm5, [rdi+0xD0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xD0], xmm5
	movdqa  xmm4, xmm15
	punpckldq xmm15, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xE0]
	paddq   xmm5, xmm15
	movdqu  [rdi+0xE0], xmm5
	movdqu  xmm5, [rdi+0xF0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xF0], xmm5
	ret
	.size	accum32, .-accum32

	.type   accum64, @function
	.balign	16
accum64:
	movdqa  xmm6, xmm8
	punpcklwd xmm6, xmm7
	punpckhwd xmm8, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi]
	paddq   xmm5, xmm6
	movdqu  [rdi], xmm5
	movdqu  xmm5, [rdi+0x10]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x10], xmm5
	movdqa  xmm4, xmm8
	punpckldq xmm8, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x20]
	paddq   xmm5, xmm8
	movdqu  [rdi+0x20], xmm5
	movdqu  xmm5, [rdi+0x30]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x30], xmm5
	movdqa  xmm6, xmm9
	punpcklwd xmm6, xmm7
	punpckhwd xmm9, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x40]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x40], xmm5
	movdqu  xmm5, [rdi+0x50]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x50], xmm5
	movdqa  xmm4, xmm9
	punpckldq xmm9, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x60]
	paddq   xmm5, xmm9
	movdqu  [rdi+0x60], xmm5
	movdqu  xmm5, [rdi+0x70]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x70], xmm5
	movdqa  xmm6, xmm10
	punpcklwd xmm6, xmm7
	punpckhwd xmm10, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x80]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x80], xmm5
	movdqu  xmm5, [rdi+0x90]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x90], xmm5
	movdqa  xmm4, xmm10
	punpckldq xmm10, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xA0]
	paddq   xmm5, xmm10
	movdqu  [rdi+0xA0], xmm5
	movdqu  xmm5, [rdi+0xB0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xB0], xmm5
	movdqa  xmm6, xmm11
	punpcklwd xmm6, xmm7
	punpckhwd xmm11, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xC0]
	paddq   xmm5, xmm6
	movdqu  [rdi+0xC0], xmm5
	movdqu  xmm5, [rdi+0xD0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xD0], xmm5
	movdqa  xmm4, xmm11
	punpckldq xmm11, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0xE0]
	paddq   xmm5, xmm11
	movdqu  [rdi+0xE0], xmm5
	movdqu  xmm5, [rdi+0xF0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0xF0], xmm5
	movdqa  xmm6, xmm12
	punpcklwd xmm6, xmm7
	punpckhwd xmm12, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x100]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x100], xmm5
	movdqu  xmm5, [rdi+0x110]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x110], xmm5
	movdqa  xmm4, xmm12
	punpckldq xmm12, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x120]
	paddq   xmm5, xmm12
	movdqu  [rdi+0x120], xmm5
	movdqu  xmm5, [rdi+0x130]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x130], xmm5
	movdqa  xmm6, xmm13
	punpcklwd xmm6, xmm7
	punpckhwd xmm13, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x140]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x140], xmm5
	movdqu  xmm5, [rdi+0x150]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x150], xmm5
	movdqa  xmm4, xmm13
	punpckldq xmm13, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x160]
	paddq   xmm5, xmm13
	movdqu  [rdi+0x160], xmm5
	movdqu  xmm5, [rdi+0x170]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x170], xmm5
	movdqa  xmm6, xmm14
	punpcklwd xmm6, xmm7
	punpckhwd xmm14, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x180]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x180], xmm5
	movdqu  xmm5, [rdi+0x190]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x190], xmm5
	movdqa  xmm4, xmm14
	punpckldq xmm14, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x1A0]
	paddq   xmm5, xmm14
	movdqu  [rdi+0x1A0], xmm5
	movdqu  xmm5, [rdi+0x1B0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x1B0], xmm5
	movdqa  xmm6, xmm15
	punpcklwd xmm6, xmm7
	punpckhwd xmm15, xmm7
	movdqa  xmm4, xmm6
	punpckldq xmm6, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x1C0]
	paddq   xmm5, xmm6
	movdqu  [rdi+0x1C0], xmm5
	movdqu  xmm5, [rdi+0x1D0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x1D0], xmm5
	movdqa  xmm4, xmm15
	punpckldq xmm15, xmm7
	punpckhdq xmm4, xmm7
	movdqu  xmm5, [rdi+0x1E0]
	paddq   xmm5, xmm15
	movdqu  [rdi+0x1E0], xmm5
	movdqu  xmm5, [rdi+0x1F0]
	paddq   xmm5, xmm4
	movdqu  [rdi+0x1F0], xmm5
	ret
	.size	accum64, .-accum64

#endif /* defined(__amd64__) */
